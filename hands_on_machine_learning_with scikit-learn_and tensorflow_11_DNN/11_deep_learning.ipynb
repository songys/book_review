{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 출처 : https://github.com/rickiepark/handson-ml\n",
    "\n",
    "스터디 발표를 위해 역자 코드를 바탕으로 내용을 추가하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ipython\n",
    "# pip install jupyter\n",
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.4\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.14.0\n",
      "sklearn 0.19.1\n",
      "scipy 1.0.0\n",
      "matplotlib 2.1.2\n",
      "tensorflow 1.5.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,sklearn,scipy,matplotlib,tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11장 – 심층 신경망 훈련**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 시각화 [참조]( http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.66315&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_이 노트북은 11장에 있는 모든 샘플 코드를 가지고 있습니다._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "심층 신경망 구현의 3가지 주요 문제    \n",
    "\n",
    "1) 그래디언트 소실(폭주 문제)    \n",
    "\n",
    "2) 훈련이 느려지는 문제    \n",
    "\n",
    "3) 과적합    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬 2와 3을 모두 지원합니다. 공통 모듈을 임포트하고 맷플롯립 그림이 노트북 안에 포함되도록 설정하고 생성한 그림을 저장하기 위한 함수를 준비합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 2와 파이썬 3 지원\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# 공통\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 일관된 출력을 위해 유사난수 초기화\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# 맷플롯립 설정\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# 한글출력 mac\n",
    "from matplotlib import rc\n",
    "rc('font', family='AppleGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "#한글출력 window\n",
    "# plt.rcParams['font.family'] = 'NanumBarunGothic'\n",
    "# plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 그림을 저장할 폴더\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그래디언트 소실/폭주 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오차 함수의 그래디언트가 경사하강법 단계의 파라미터 수정 단계에서 점점 작아져서 가중치가 변경되지 않는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xavier Glorot와 Yoshua Bengio의 [관련 논문](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)참조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 활성화 함수를 보면 아래 그림 처림 절댓값이 0이나 1로 수렴해서 기울기가 0에 매우 가까워지는 것을 볼 수 있다. 그래서 역전파가 될 때 사실상 신경망으로 전파시킬 그래디언트가 거의 없고 조금 있는 그래디언트는 최상위에서부터 역전파가 진행됨에 따라 점점 약해져서 실제로 아래층에 도달시킬 것이 없게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1227c4ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('수렴', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('수렴', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('선형', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"로지스틱 활성화 함수\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"sigmoid_saturation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavier와 He 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세이비어 초기화 메인 아이디어: 마이크 볼륨이 0에 가까우면 안들리고 반대로 최대치면 너무 시끄러워서 무슨 말인지 모르게 됩니다. 잘 들리려면 모든 증폭기가 적절하게 설정하기 위해서는 입력 목소리이 크기와 출력 목소리의 크기와 같도록 적절하게 설정해야 할 것입니다. \n",
    "이처럼 입력층의 분산과 출력층의 분산이 같도록 하는 것.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연결 가중치를 다음 식과 같이 무작위로 초기화 하여 작동하도록 하는 방식으로 여기서 n <sub>inputs</sub> 와 n <sub>outputs</sub>  는 가중치를 초기화하려는 층의 입력과 출력 연결의 개수입니다. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "xavier - 입력값과 출력값 사이의 난수를 선택해서 입력값의 제곱근으로 나눕니다.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "σ = 1/\\sqrt n ~inputs~\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "he - 입력값을 반으로 나눈 제곱근 사용. 분모가 작아지기 때문에 xavier보다 넓은 범위의 난수 생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\") \n",
    "\n",
    "#형태(shape)를 정의하고 None 을 이용하여 임의의 batch size를 핸들링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 로드 : MNIST는 greyscale인 손글씨 이미지를 보고 1에서 9까지 숫자 중 어떤 것인지 맞추는 데이터입니다. \n",
    "28x28 픽셀 이미지로 되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"mnist.png\", width = \"500\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[데이터 시각화 참조](http://colah.github.io/posts/2014-10-Visualizing-MNIST/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                          kernel_initializer=he_init, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로에서는 변수를 생성하는 함수로 `get_variable()`이나  `tf.layers.dense()`를 제공합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수렴하지 않는 활성화 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"sig_01.jpeg\", width=\"500\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"sig_02.jpeg\", width=\"500\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU 정의 : <p>$$f(x)=max(0,x)$$</p>\n",
    "\n",
    "x가 양수이기만 하면 그래디언트는 1 로 일정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLu함수는 입력이 음수면 그래디언트가 0이 되기 때문에 일부 뉴런이 0이외의 값을 출력하지 않는 문제가 생겼습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaky ReLU 정의 : <p>$$f(x)=max(0.01x,x)$$</p>\n",
    "x가 음수일 때 그래디언트가 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122887a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('통과', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU 활성화 함수\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "save_fig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로에서 Leaky ReLU 구현하기:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_텐서플로 1.4에서 tf.nn.leaky_\\__relu(z, alpha) 함수가 추가되었습니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaky ReLU를 사용하여 신경망을 훈련시켜 보죠. \n",
    "\n",
    "## 먼저 그래프를 정의합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"softmax.png\", width=\"800\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 [출처](https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/tutorials/mnist/beginners/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "#학습 비율 0.01로 경사하강법을 써서 cross_entropy를 줄여주고 텐서플로우에서는 경사하강의 그래프 추가함\n",
    "#Optimizer : 모델이 loss(predictions 와 labels 사이의 차이)를 최소화 하는 방향으로 파라미터 업데이트\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saver로 전체 매개변수 변수 초기화하여 가중치(weight)와 편향(bias)를 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로드\n",
    "\n",
    "주의: `tf.examples.tutorials.mnist`은 삭제될 예정이므로 대신 `tf.keras.datasets.mnist`를 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 데이터는 [image index, pixel index] 형태의 이차원 텐서(여기선 2차원 배열을 의미함)로 추출될 수 있습니다. 각 엔트리는 특정 이미지에서 특정 픽셀의 휘도값(Luminance)이며, [0, 255]에서 [0, 1]까지 재조정됩니다 \n",
    "\n",
    "\n",
    "[참조](https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/tutorials/mnist/download/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배치 \n",
    "\n",
    "매 단계마다 전체 데이터를 사용할 수 없으므로 무작위 데이터를 사용하여 graph 에 feed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 배치 데이터 정확도: 0.86 검증 세트 정확도: 0.9046\n",
      "5 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9496\n",
      "10 배치 데이터 정확도: 0.92 검증 세트 정확도: 0.9654\n",
      "15 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9708\n",
      "20 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9764\n",
      "25 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9774\n",
      "30 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.978\n",
      "35 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9784\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "#반복되는 루프마다 학습 데이터셋을 무작위로 50개씩 가져옵니다.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"배치 데이터 정확도:\", acc_batch, \"검증 세트 정확도:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential Linear Units \n",
    "\n",
    "<p>$$ f(x)=x   \\      \\                   if\\        x>0  $$</p>\n",
    "\n",
    "<p>$$ f(x)=α(e^x −1) \\      \\      if\\        x≤0 $$</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12292de80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU 활성화 함수 ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로에서 ELU를 구현하는 것은 간단합니다. 층을 구성할 때 활성화 함수에 지정하기만 하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-Normalizing Neural Networks : 이 활성화 함수는 Günter Klambauer, Thomas Unterthiner, Andreas Mayr가 2017년에 쓴 [논문](https://arxiv.org/pdf/1706.02515.pdf)에서 소개되었습니다. 훈련할 때 SELU 활성화 함수를 사용한 완전 연결 신경망은 스스로 정규화를 합니다. 각 층의 출력은 훈련하는 동안 같은 평균과 분산을 유지하려는 경향이 있어 그래디언트 소실과 폭주 문제를 해결합니다. 이 활성화 함수는 심층 신경망에서 다른 활성화 함수보다 뛰어난 성능을 내므로 꼭 이 함수를 시도해봐야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"selu.png\" width=\"500\"><BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z,\n",
    "         scale=1.0507009873554804934193349852946,\n",
    "         alpha=1.6732632423543772848170429916717):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1224a6320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"SELU 활성화 함수\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"selu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 SELU 하이퍼파라미터(`scale`과 `alpha`)는 평균이 0, 표준 편차가 1에 가깝게 유지되도록 조정합니다(입력도 평균이 0, 표준 편차가 1로 표준화되었다고 가정합니다). 이 활성화 함수를 사용하면 100층으로 된 심층 신경망도 그래디언트 소실/폭주 문제없이 모든 층에서 대략 평균이 0이고 표준 편차가 1을 유지합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "층 0: -0.26 < 평균 < 0.27, 0.74 < 표준 편차 < 1.27\n",
      "층 10: -0.24 < 평균 < 0.27, 0.74 < 표준 편차 < 1.27\n",
      "층 20: -0.17 < 평균 < 0.18, 0.74 < 표준 편차 < 1.24\n",
      "층 30: -0.27 < 평균 < 0.24, 0.78 < 표준 편차 < 1.20\n",
      "층 40: -0.38 < 평균 < 0.39, 0.74 < 표준 편차 < 1.25\n",
      "층 50: -0.27 < 평균 < 0.31, 0.73 < 표준 편차 < 1.27\n",
      "층 60: -0.26 < 평균 < 0.43, 0.74 < 표준 편차 < 1.35\n",
      "층 70: -0.19 < 평균 < 0.21, 0.75 < 표준 편차 < 1.21\n",
      "층 80: -0.18 < 평균 < 0.16, 0.72 < 표준 편차 < 1.19\n",
      "층 90: -0.19 < 평균 < 0.16, 0.75 < 표준 편차 < 1.20\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100))\n",
    "for layer in range(100):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1/100))\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=1)\n",
    "    stds = np.std(Z, axis=1)\n",
    "    if layer % 10 == 0:\n",
    "        print(\"층 {}: {:.2f} < 평균 < {:.2f}, {:.2f} < 표준 편차 < {:.2f}\".format(\n",
    "            layer, means.min(), means.max(), stds.min(), stds.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로 1.4 버전에 `tf.nn.selu()` 함수가 추가되었습니다. 이전 버전을 사용할 때는 다음 구현을 사용합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z,\n",
    "         scale=1.0507009873554804934193349852946,\n",
    "         alpha=1.6732632423543772848170429916717):\n",
    "    return scale * tf.where(z >= 0.0, z, alpha * tf.nn.elu(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 SELU 활성화 함수는 일반적인 드롭아웃과 함께 사용할 수 없습니다(드롭아웃은 SELU 활성화 함수의 자동 정규화 기능을 없애버립니다). 다행히 같은 논문에 실린 알파 드롭아웃(Alpha Dropout)을 사용할 수 있습니다. 텐서플로 1.4에 `tf.contrib.nn.alpha_dropout()`이 추가되었습니다(Linz 대학교 생물정보학 연구소(Institute of Bioinformatics)의 Johannes Kepler가 만든 [구현](https://github.com/bioinf-jku/SNNs/blob/master/selu.py)을 확인해 보세요)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELU 활성화 함수를 사용한 신경망을 만들어 MNIST 문제를 풀어 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=selu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=selu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이제 훈련할 차례입니다. \n",
    "\n",
    "입력을 평균 0, 표준 편차 1로 스케일 조정해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 배치 데이터 정확도: 0.88 검증 세트 정확도: 0.923\n",
      "5 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9574\n",
      "10 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9662\n",
      "15 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9682\n",
      "20 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9692\n",
      "25 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9688\n",
      "30 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9694\n",
      "35 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.97\n"
     ]
    }
   ],
   "source": [
    "means = X_train.mean(axis=0, keepdims=True)\n",
    "stds = X_train.std(axis=0, keepdims=True) + 1e-10\n",
    "X_val_scaled = (X_valid - means) / stds\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            X_batch_scaled = (X_batch - means) / stds\n",
    "            sess.run(training_op, feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_val_scaled, y: y_valid})\n",
    "            print(epoch, \"배치 데이터 정확도:\", acc_batch, \"검증 세트 정확도:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final_selu.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배치 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELU와 함께 HE 초기화를 사용하면 훈련 초기 단계에서는 그래디언트 소실문제가 크게 줄어들지만 훈련하는 동안 그 문제가 다시 발생하지 않으리란 보장이 없습니다. 좀 더 일반적인 설명으로는 훈련하는 동안 이전 층의 파라미터가 변함에 따라 각 층에 들어오는 입력의 분포가 변하는 문제(내부 공변량 변화 문제)입니다. 이를 해결하기 위해 Sergey Ioffe와 Christian Szegedy의 [논문](https://arxiv.org/pdf/1502.03167v3.pdf)에서 배치 정규화를 제안하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 은닉층의 활성화 함수 전에 배치 정규화를 추가하기 위해 ELU 활성화 함수를 배치 정규화 층 이후에 수동으로 적용하겠습니다.\n",
    "\n",
    "노트: `tf.layers.dense()` 함수가 (책에서 사용하는) `tf.contrib.layers.arg_scope()`와 호환되지 않기 때문에 대신 파이썬의 `functools.partial()` 함수를 사용합니다. 이를 사용해 `tf.layers.dense()`에 필요한 매개변수가 자동으로 설정되도록 `my_dense_layer()`를 만듭니다(그렇지 않으면 `my_dense_layer()`를 호출할 때마다 덮어씌여질 것입니다). 다른 코드는 이전과 비슷합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "#placeholder()함수는 첫번째 매개변수로 데이터 타입을 넘겨받고 \n",
    "#placeholder_with_default()함수로 첫 번째 매개변수로 플레이스홀더의 기본값을 넘겨받습니다.\n",
    "#traing하는 동안은 True로 그 외에는 False로 설정합니다.\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "#tf.layers.batch_normalization()함수가 훈련할 때 현재 미니배치의 평균과 표준편차를 사용할 지 \n",
    "#또는 테스트할 때 전체 훈련 세트에 대한 평균과 표준편차를 사용할 지 지정합니다.\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "#적절한 momentum값는 일반적으로 1에 가깝습니다. 예를 들면 0.9, 0.99, 0.999입니다.\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같은 매개변수를 계속 반복해서 쓰지 않도록 파이썬의 `partial()` 함수를 사용합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization,\n",
    "                              training=training, momentum=0.9)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 층에 ELU 활성화 함수와 배치 정규화를 사용하여 MNIST를 위한 신경망을 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "노트: 배치 정규화를 위해 별도의 업데이트 연산을 실행해 주어야 합니다(`sess.run([training_op, extra_update_ops],...`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9042\n",
      "1 검증 세트 정확도: 0.928\n",
      "2 검증 세트 정확도: 0.9374\n",
      "3 검증 세트 정확도: 0.9474\n",
      "4 검증 세트 정확도: 0.9532\n",
      "5 검증 세트 정확도: 0.9572\n",
      "6 검증 세트 정확도: 0.9626\n",
      "7 검증 세트 정확도: 0.9628\n",
      "8 검증 세트 정확도: 0.9664\n",
      "9 검증 세트 정확도: 0.968\n",
      "10 검증 세트 정확도: 0.9694\n",
      "11 검증 세트 정확도: 0.9696\n",
      "12 검증 세트 정확도: 0.971\n",
      "13 검증 세트 정확도: 0.971\n",
      "14 검증 세트 정확도: 0.9728\n",
      "15 검증 세트 정확도: 0.9734\n",
      "16 검증 세트 정확도: 0.9728\n",
      "17 검증 세트 정확도: 0.975\n",
      "18 검증 세트 정확도: 0.9752\n",
      "19 검증 세트 정확도: 0.976\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어!? MNIST 정확도가 좋지 않네요. 물론 훈련을 더 오래하면 정확도가 높아지겠지만 이런 얕은 신경망에서는 배치 정규화와 ELU가 큰 효과를 내지 못합니다. 대부분 심층 신경망에서 빛을 발합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "업데이트 연산에 의존하는 훈련 연산을 만들 수도 있습니다:\n",
    "\n",
    "```python\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(extra_update_ops):\n",
    "        training_op = optimizer.minimize(loss)\n",
    "```\n",
    "\n",
    "이렇게 하면 훈련할 때 `training_op`만 평가하면 텐서플로가 업데이트 연산도 자동으로 실행할 것입니다:\n",
    "\n",
    "```python\n",
    "sess.run(training_op, feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한가지 더, 훈련될 변수 개수가 전체 전역 변수 개수보다 적습니다. 이동 평균을 위한 변수는 훈련되는 변수가 아니기 때문입니다. 미리 학습한 신경망을 재사용할 경우(아래 참조) 이런 훈련되지 않는 변수를 놓쳐서는 안됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.trainable_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'batch_normalization/moving_mean:0',\n",
       " 'batch_normalization/moving_variance:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'batch_normalization_1/moving_mean:0',\n",
       " 'batch_normalization_1/moving_variance:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0',\n",
       " 'batch_normalization_2/moving_mean:0',\n",
       " 'batch_normalization_2/moving_variance:0']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래디언트 클리핑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST를 위한 간단한 신경망을 만들고 그래디언트 클리핑을 적용해 보겠습니다. 시작 부분은 이전과 동일합니다(학습한 모델을 재사용하는 예를 만들기 위해 몇 개의 층을 더 추가했습니다. 아래 참조):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 그래디언트 클리핑을 적용합니다. 먼저 그래디언트를 구한 다음 `clip_by_value()` 함수를 사용해 클리핑하고 적용합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나머지는 이전과 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.288\n",
      "1 검증 세트 정확도: 0.7938\n",
      "2 검증 세트 정확도: 0.8796\n",
      "3 검증 세트 정확도: 0.9058\n",
      "4 검증 세트 정확도: 0.9164\n",
      "5 검증 세트 정확도: 0.9218\n",
      "6 검증 세트 정확도: 0.9292\n",
      "7 검증 세트 정확도: 0.9358\n",
      "8 검증 세트 정확도: 0.938\n",
      "9 검증 세트 정확도: 0.9416\n",
      "10 검증 세트 정확도: 0.9456\n",
      "11 검증 세트 정확도: 0.9472\n",
      "12 검증 세트 정확도: 0.9476\n",
      "13 검증 세트 정확도: 0.953\n",
      "14 검증 세트 정확도: 0.9566\n",
      "15 검증 세트 정확도: 0.9566\n",
      "16 검증 세트 정확도: 0.9578\n",
      "17 검증 세트 정확도: 0.9586\n",
      "18 검증 세트 정확도: 0.9624\n",
      "19 검증 세트 정확도: 0.9614\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 모델 재사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로 모델 재사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"transfer.png\" width='500'><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note) 만약 원래 문제에서 사용한 것과 크기가 다른 이미지를 입력으로 사용한다면 원본 모델에 맞는 크기로 변경하는 전처리 단계를 추가해야 합니다. 일반적으로 전이 학습은 입력이 비슷한 저수준 특성을 가질 때 잘 작동합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 그래프 구조를 로드해야 합니다. `import_meta_graph()` 함수가 그래프 연산들을 로드하여 기본 그래프에 적재하고 모델의 상태를 복원할 수 있도록 `Saver` 객체를 반환합니다. 기본적으로 `Saver` 객체는 `.meta` 확장자를 가진 파일에 그래프 구조를 저장하므로 이 파일을 로드해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 훈련해야 할 모든 연산을 가져와야 합니다. 그래프 구조를 모를 때는 모든 연산을 출력해 볼 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "y\n",
      "hidden1/kernel/Initializer/random_uniform/shape\n",
      "hidden1/kernel/Initializer/random_uniform/min\n",
      "hidden1/kernel/Initializer/random_uniform/max\n",
      "hidden1/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden1/kernel/Initializer/random_uniform/sub\n",
      "hidden1/kernel/Initializer/random_uniform/mul\n",
      "hidden1/kernel/Initializer/random_uniform\n",
      "hidden1/kernel\n",
      "hidden1/kernel/Assign\n",
      "hidden1/kernel/read\n",
      "hidden1/bias/Initializer/zeros\n",
      "hidden1/bias\n",
      "hidden1/bias/Assign\n",
      "hidden1/bias/read\n",
      "dnn/hidden1/MatMul\n",
      "dnn/hidden1/BiasAdd\n",
      "dnn/hidden1/Relu\n",
      "hidden2/kernel/Initializer/random_uniform/shape\n",
      "hidden2/kernel/Initializer/random_uniform/min\n",
      "hidden2/kernel/Initializer/random_uniform/max\n",
      "hidden2/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden2/kernel/Initializer/random_uniform/sub\n",
      "hidden2/kernel/Initializer/random_uniform/mul\n",
      "hidden2/kernel/Initializer/random_uniform\n",
      "hidden2/kernel\n",
      "hidden2/kernel/Assign\n",
      "hidden2/kernel/read\n",
      "hidden2/bias/Initializer/zeros\n",
      "hidden2/bias\n",
      "hidden2/bias/Assign\n",
      "hidden2/bias/read\n",
      "dnn/hidden2/MatMul\n",
      "dnn/hidden2/BiasAdd\n",
      "dnn/hidden2/Relu\n",
      "hidden3/kernel/Initializer/random_uniform/shape\n",
      "hidden3/kernel/Initializer/random_uniform/min\n",
      "hidden3/kernel/Initializer/random_uniform/max\n",
      "hidden3/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden3/kernel/Initializer/random_uniform/sub\n",
      "hidden3/kernel/Initializer/random_uniform/mul\n",
      "hidden3/kernel/Initializer/random_uniform\n",
      "hidden3/kernel\n",
      "hidden3/kernel/Assign\n",
      "hidden3/kernel/read\n",
      "hidden3/bias/Initializer/zeros\n",
      "hidden3/bias\n",
      "hidden3/bias/Assign\n",
      "hidden3/bias/read\n",
      "dnn/hidden3/MatMul\n",
      "dnn/hidden3/BiasAdd\n",
      "dnn/hidden3/Relu\n",
      "hidden4/kernel/Initializer/random_uniform/shape\n",
      "hidden4/kernel/Initializer/random_uniform/min\n",
      "hidden4/kernel/Initializer/random_uniform/max\n",
      "hidden4/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden4/kernel/Initializer/random_uniform/sub\n",
      "hidden4/kernel/Initializer/random_uniform/mul\n",
      "hidden4/kernel/Initializer/random_uniform\n",
      "hidden4/kernel\n",
      "hidden4/kernel/Assign\n",
      "hidden4/kernel/read\n",
      "hidden4/bias/Initializer/zeros\n",
      "hidden4/bias\n",
      "hidden4/bias/Assign\n",
      "hidden4/bias/read\n",
      "dnn/hidden4/MatMul\n",
      "dnn/hidden4/BiasAdd\n",
      "dnn/hidden4/Relu\n",
      "hidden5/kernel/Initializer/random_uniform/shape\n",
      "hidden5/kernel/Initializer/random_uniform/min\n",
      "hidden5/kernel/Initializer/random_uniform/max\n",
      "hidden5/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden5/kernel/Initializer/random_uniform/sub\n",
      "hidden5/kernel/Initializer/random_uniform/mul\n",
      "hidden5/kernel/Initializer/random_uniform\n",
      "hidden5/kernel\n",
      "hidden5/kernel/Assign\n",
      "hidden5/kernel/read\n",
      "hidden5/bias/Initializer/zeros\n",
      "hidden5/bias\n",
      "hidden5/bias/Assign\n",
      "hidden5/bias/read\n",
      "dnn/hidden5/MatMul\n",
      "dnn/hidden5/BiasAdd\n",
      "dnn/hidden5/Relu\n",
      "outputs/kernel/Initializer/random_uniform/shape\n",
      "outputs/kernel/Initializer/random_uniform/min\n",
      "outputs/kernel/Initializer/random_uniform/max\n",
      "outputs/kernel/Initializer/random_uniform/RandomUniform\n",
      "outputs/kernel/Initializer/random_uniform/sub\n",
      "outputs/kernel/Initializer/random_uniform/mul\n",
      "outputs/kernel/Initializer/random_uniform\n",
      "outputs/kernel\n",
      "outputs/kernel/Assign\n",
      "outputs/kernel/read\n",
      "outputs/bias/Initializer/zeros\n",
      "outputs/bias\n",
      "outputs/bias/Assign\n",
      "outputs/bias/read\n",
      "dnn/outputs/MatMul\n",
      "dnn/outputs/BiasAdd\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/Shape\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n",
      "loss/Const\n",
      "loss/loss\n",
      "gradients/Shape\n",
      "gradients/grad_ys_0\n",
      "gradients/Fill\n",
      "gradients/loss/loss_grad/Reshape/shape\n",
      "gradients/loss/loss_grad/Reshape\n",
      "gradients/loss/loss_grad/Shape\n",
      "gradients/loss/loss_grad/Tile\n",
      "gradients/loss/loss_grad/Shape_1\n",
      "gradients/loss/loss_grad/Shape_2\n",
      "gradients/loss/loss_grad/Const\n",
      "gradients/loss/loss_grad/Prod\n",
      "gradients/loss/loss_grad/Const_1\n",
      "gradients/loss/loss_grad/Prod_1\n",
      "gradients/loss/loss_grad/Maximum/y\n",
      "gradients/loss/loss_grad/Maximum\n",
      "gradients/loss/loss_grad/floordiv\n",
      "gradients/loss/loss_grad/Cast\n",
      "gradients/loss/loss_grad/truediv\n",
      "gradients/zeros_like\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul\n",
      "gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul_1\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1\n",
      "clip_by_value/Minimum/y\n",
      "clip_by_value/Minimum\n",
      "clip_by_value/y\n",
      "clip_by_value\n",
      "clip_by_value_1/Minimum/y\n",
      "clip_by_value_1/Minimum\n",
      "clip_by_value_1/y\n",
      "clip_by_value_1\n",
      "clip_by_value_2/Minimum/y\n",
      "clip_by_value_2/Minimum\n",
      "clip_by_value_2/y\n",
      "clip_by_value_2\n",
      "clip_by_value_3/Minimum/y\n",
      "clip_by_value_3/Minimum\n",
      "clip_by_value_3/y\n",
      "clip_by_value_3\n",
      "clip_by_value_4/Minimum/y\n",
      "clip_by_value_4/Minimum\n",
      "clip_by_value_4/y\n",
      "clip_by_value_4\n",
      "clip_by_value_5/Minimum/y\n",
      "clip_by_value_5/Minimum\n",
      "clip_by_value_5/y\n",
      "clip_by_value_5\n",
      "clip_by_value_6/Minimum/y\n",
      "clip_by_value_6/Minimum\n",
      "clip_by_value_6/y\n",
      "clip_by_value_6\n",
      "clip_by_value_7/Minimum/y\n",
      "clip_by_value_7/Minimum\n",
      "clip_by_value_7/y\n",
      "clip_by_value_7\n",
      "clip_by_value_8/Minimum/y\n",
      "clip_by_value_8/Minimum\n",
      "clip_by_value_8/y\n",
      "clip_by_value_8\n",
      "clip_by_value_9/Minimum/y\n",
      "clip_by_value_9/Minimum\n",
      "clip_by_value_9/y\n",
      "clip_by_value_9\n",
      "clip_by_value_10/Minimum/y\n",
      "clip_by_value_10/Minimum\n",
      "clip_by_value_10/y\n",
      "clip_by_value_10\n",
      "clip_by_value_11/Minimum/y\n",
      "clip_by_value_11/Minimum\n",
      "clip_by_value_11/y\n",
      "clip_by_value_11\n",
      "GradientDescent/learning_rate\n",
      "GradientDescent/update_hidden1/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden1/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/bias/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/bias/ApplyGradientDescent\n",
      "GradientDescent\n",
      "eval/in_top_k/InTopKV2/k\n",
      "eval/in_top_k/InTopKV2\n",
      "eval/Cast\n",
      "eval/Const\n",
      "eval/accuracy\n",
      "init\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/RestoreV2_1/tensor_names\n",
      "save/RestoreV2_1/shape_and_slices\n",
      "save/RestoreV2_1\n",
      "save/Assign_1\n",
      "save/RestoreV2_2/tensor_names\n",
      "save/RestoreV2_2/shape_and_slices\n",
      "save/RestoreV2_2\n",
      "save/Assign_2\n",
      "save/RestoreV2_3/tensor_names\n",
      "save/RestoreV2_3/shape_and_slices\n",
      "save/RestoreV2_3\n",
      "save/Assign_3\n",
      "save/RestoreV2_4/tensor_names\n",
      "save/RestoreV2_4/shape_and_slices\n",
      "save/RestoreV2_4\n",
      "save/Assign_4\n",
      "save/RestoreV2_5/tensor_names\n",
      "save/RestoreV2_5/shape_and_slices\n",
      "save/RestoreV2_5\n",
      "save/Assign_5\n",
      "save/RestoreV2_6/tensor_names\n",
      "save/RestoreV2_6/shape_and_slices\n",
      "save/RestoreV2_6\n",
      "save/Assign_6\n",
      "save/RestoreV2_7/tensor_names\n",
      "save/RestoreV2_7/shape_and_slices\n",
      "save/RestoreV2_7\n",
      "save/Assign_7\n",
      "save/RestoreV2_8/tensor_names\n",
      "save/RestoreV2_8/shape_and_slices\n",
      "save/RestoreV2_8\n",
      "save/Assign_8\n",
      "save/RestoreV2_9/tensor_names\n",
      "save/RestoreV2_9/shape_and_slices\n",
      "save/RestoreV2_9\n",
      "save/Assign_9\n",
      "save/RestoreV2_10/tensor_names\n",
      "save/RestoreV2_10/shape_and_slices\n",
      "save/RestoreV2_10\n",
      "save/Assign_10\n",
      "save/RestoreV2_11/tensor_names\n",
      "save/RestoreV2_11/shape_and_slices\n",
      "save/RestoreV2_11\n",
      "save/Assign_11\n",
      "save/restore_all\n"
     ]
    }
   ],
   "source": [
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "웁스, 연산이 엄청 많네요! 텐서보드로 그래프를 시각화해보는 것이 더 좋을 것 같습니다. 다음 코드는 주피터에서 그래프를 그려줍니다(만약 브라우저에서 보이지 않는다면 `FileWriter`로 그래프를 저장한 다음 텐서보드에서 열어 보세요):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow_graph_in_jupyter.py에서 그래프를 임포트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_graph_in_jupyter import show_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.3745401188473625&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 5\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;hidden1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.13093073666095734\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.13093073666095734\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 22\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;hidden2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 39\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;hidden3/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden3/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden3/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;hidden3/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden3/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden3/MatMul&quot;\\n  input: &quot;hidden3/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden3/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden3/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 56\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;hidden4/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden4/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden4/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden3/Relu&quot;\\n  input: &quot;hidden4/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden4/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden4/MatMul&quot;\\n  input: &quot;hidden4/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden4/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden4/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 73\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;hidden5/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden5/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden5/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden4/Relu&quot;\\n  input: &quot;hidden5/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden5/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden5/MatMul&quot;\\n  input: &quot;hidden5/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden5/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden5/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.3162277638912201\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.3162277638912201\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 90\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden5/Relu&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;outputs/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/loss/loss_grad/Reshape&quot;\\n  input: &quot;gradients/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/loss/loss_grad/Shape_1&quot;\\n  input: &quot;gradients/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/loss/loss_grad/Shape_2&quot;\\n  input: &quot;gradients/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/loss/loss_grad/Prod_1&quot;\\n  input: &quot;gradients/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/loss/loss_grad/Prod&quot;\\n  input: &quot;gradients/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/loss/loss_grad/Tile&quot;\\n  input: &quot;gradients/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/loss/loss_grad/truediv&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden5/Relu&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden5/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden5/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden4/Relu&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden4/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden4/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden3/Relu&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden3/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden3/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value/Minimum&quot;\\n  input: &quot;clip_by_value/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_1/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_1/Minimum&quot;\\n  input: &quot;clip_by_value_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_2/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_2/Minimum&quot;\\n  input: &quot;clip_by_value_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_3/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_3/Minimum&quot;\\n  input: &quot;clip_by_value_3/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_4/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_4/Minimum&quot;\\n  input: &quot;clip_by_value_4/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_5/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_5/Minimum&quot;\\n  input: &quot;clip_by_value_5/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_6/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_6/Minimum&quot;\\n  input: &quot;clip_by_value_6/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_7/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_7/Minimum&quot;\\n  input: &quot;clip_by_value_7/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_8/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_8/Minimum&quot;\\n  input: &quot;clip_by_value_8/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_9/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_9/Minimum&quot;\\n  input: &quot;clip_by_value_9/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_10/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_10/Minimum&quot;\\n  input: &quot;clip_by_value_10/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_11/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_11/Minimum&quot;\\n  input: &quot;clip_by_value_11/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden3/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden3/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden4/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden4/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden5/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden5/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden3/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden3/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden4/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden4/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden5/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden5/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;eval/in_top_k/InTopKV2/k&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/in_top_k/InTopKV2&quot;\\n  op: &quot;InTopKV2&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  input: &quot;eval/in_top_k/InTopKV2/k&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;eval/in_top_k/InTopKV2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/accuracy&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;eval/Cast&quot;\\n  input: &quot;eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^hidden1/kernel/Assign&quot;\\n  input: &quot;^hidden1/bias/Assign&quot;\\n  input: &quot;^hidden2/kernel/Assign&quot;\\n  input: &quot;^hidden2/bias/Assign&quot;\\n  input: &quot;^hidden3/kernel/Assign&quot;\\n  input: &quot;^hidden3/bias/Assign&quot;\\n  input: &quot;^hidden4/kernel/Assign&quot;\\n  input: &quot;^hidden4/bias/Assign&quot;\\n  input: &quot;^hidden5/kernel/Assign&quot;\\n  input: &quot;^hidden5/bias/Assign&quot;\\n  input: &quot;^outputs/kernel/Assign&quot;\\n  input: &quot;^outputs/bias/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 12\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n        string_val: &quot;hidden1/kernel&quot;\\n        string_val: &quot;hidden2/bias&quot;\\n        string_val: &quot;hidden2/kernel&quot;\\n        string_val: &quot;hidden3/bias&quot;\\n        string_val: &quot;hidden3/kernel&quot;\\n        string_val: &quot;hidden4/bias&quot;\\n        string_val: &quot;hidden4/kernel&quot;\\n        string_val: &quot;hidden5/bias&quot;\\n        string_val: &quot;hidden5/kernel&quot;\\n        string_val: &quot;outputs/bias&quot;\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 12\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_2/tensor_names&quot;\\n  input: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;save/RestoreV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_3/tensor_names&quot;\\n  input: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;save/RestoreV2_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden3/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_4/tensor_names&quot;\\n  input: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;save/RestoreV2_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_5/tensor_names&quot;\\n  input: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;save/RestoreV2_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_6/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden4/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_6/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_6&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_6/tensor_names&quot;\\n  input: &quot;save/RestoreV2_6/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_6&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;save/RestoreV2_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_7/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_7/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_7&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_7/tensor_names&quot;\\n  input: &quot;save/RestoreV2_7/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_7&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;save/RestoreV2_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_8/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden5/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_8/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_8&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_8/tensor_names&quot;\\n  input: &quot;save/RestoreV2_8/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_8&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;save/RestoreV2_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_9/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_9/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_9&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_9/tensor_names&quot;\\n  input: &quot;save/RestoreV2_9/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_9&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;save/RestoreV2_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_10/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_10/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_10&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_10/tensor_names&quot;\\n  input: &quot;save/RestoreV2_10/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_10&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;save/RestoreV2_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_11/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_11/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_11&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_11/tensor_names&quot;\\n  input: &quot;save/RestoreV2_11/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_11&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;save/RestoreV2_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n  input: &quot;^save/Assign_6&quot;\\n  input: &quot;^save/Assign_7&quot;\\n  input: &quot;^save/Assign_8&quot;\\n  input: &quot;^save/Assign_9&quot;\\n  input: &quot;^save/Assign_10&quot;\\n  input: &quot;^save/Assign_11&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.3745401188473625&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요한 연산을 찾았다면 그래프의 `get_operation_by_name()`이나 `get_tensor_by_name()` 메서드를 사용하여 추출할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")\n",
    "\n",
    "training_op = tf.get_default_graph().get_operation_by_name(\"GradientDescent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 모델을 만들 때 다른 사람이 재사용하기 쉽게 연산에 명확한 이름을 부여하고 문서화를 하는 것이 좋습니다. 또 다른 방법은 처리해야 할 중요한 연산들을 모두 모아 놓은 컬렉션을 만드는 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in (X, y, accuracy, training_op):\n",
    "    tf.add_to_collection(\"my_important_ops\", op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 하면 모델을 재사용할 때 다음과 같이 간단하게 쓸 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, accuracy, training_op = tf.get_collection(\"my_important_ops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 세션을 시작하고 모델을 복원하여 준비된 훈련 데이터로 훈련을 계속할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    # 모델 훈련 계속하기..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 테스트를 해보죠!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9632\n",
      "1 검증 세트 정확도: 0.963\n",
      "2 검증 세트 정확도: 0.9654\n",
      "3 검증 세트 정확도: 0.965\n",
      "4 검증 세트 정확도: 0.9644\n",
      "5 검증 세트 정확도: 0.965\n",
      "6 검증 세트 정확도: 0.9688\n",
      "7 검증 세트 정확도: 0.9682\n",
      "8 검증 세트 정확도: 0.9682\n",
      "9 검증 세트 정확도: 0.9686\n",
      "10 검증 세트 정확도: 0.9704\n",
      "11 검증 세트 정확도: 0.9714\n",
      "12 검증 세트 정확도: 0.967\n",
      "13 검증 세트 정확도: 0.9702\n",
      "14 검증 세트 정확도: 0.9706\n",
      "15 검증 세트 정확도: 0.972\n",
      "16 검증 세트 정확도: 0.972\n",
      "17 검증 세트 정확도: 0.971\n",
      "18 검증 세트 정확도: 0.9712\n",
      "19 검증 세트 정확도: 0.9714\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 방법으로 원본 그래프를 만든 파이썬 코드에 접근할 수 있다면 `import_meta_graph()`를 대신 사용할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음 훈련을 계속할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9642\n",
      "1 검증 세트 정확도: 0.963\n",
      "2 검증 세트 정확도: 0.9652\n",
      "3 검증 세트 정확도: 0.965\n",
      "4 검증 세트 정확도: 0.964\n",
      "5 검증 세트 정확도: 0.965\n",
      "6 검증 세트 정확도: 0.9688\n",
      "7 검증 세트 정확도: 0.9684\n",
      "8 검증 세트 정확도: 0.9684\n",
      "9 검증 세트 정확도: 0.9688\n",
      "10 검증 세트 정확도: 0.9704\n",
      "11 검증 세트 정확도: 0.9716\n",
      "12 검증 세트 정확도: 0.9674\n",
      "13 검증 세트 정확도: 0.9702\n",
      "14 검증 세트 정확도: 0.9706\n",
      "15 검증 세트 정확도: 0.9724\n",
      "16 검증 세트 정확도: 0.9716\n",
      "17 검증 세트 정확도: 0.9712\n",
      "18 검증 세트 정확도: 0.9712\n",
      "19 검증 세트 정확도: 0.9714\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 하위층만 재사용할 것입니다. `import_meta_graph()`를 사용하면 전체 그래프를 로드하지만 필요하지 않은 부분은 무시하면 됩니다. 이 예에서는 학습된 3번째 층 위에 4번째 은닉층을 새로 추가합니다(원래 4번째 층은 무시됩니다). 새로운 출력층도 추가하고 이 출력으로 손실을 계산하고 이를 최소화하기 위한 새로운 옵티마이저를 만듭니다. 전체 그래프(원본 그래프 전체와 새로운 연산)를 저장할 새로운 `Saver` 객체와 새로운 모든 변수를 초기화할 초기화 연산도 필요합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_hidden4 = 20  # 새 층\n",
    "n_outputs = 10  # 새 층\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden3 = tf.get_default_graph().get_tensor_by_name(\"dnn/hidden4/Relu:0\")\n",
    "\n",
    "new_hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"new_hidden4\")\n",
    "new_logits = tf.layers.dense(new_hidden4, n_outputs, name=\"new_outputs\")\n",
    "\n",
    "with tf.name_scope(\"new_loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"new_eval\"):\n",
    "    correct = tf.nn.in_top_k(new_logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"new_train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새로운 모델을 훈련시킵니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.8756\n",
      "1 검증 세트 정확도: 0.9388\n",
      "2 검증 세트 정확도: 0.9494\n",
      "3 검증 세트 정확도: 0.9518\n",
      "4 검증 세트 정확도: 0.954\n",
      "5 검증 세트 정확도: 0.956\n",
      "6 검증 세트 정확도: 0.9608\n",
      "7 검증 세트 정확도: 0.9622\n",
      "8 검증 세트 정확도: 0.9616\n",
      "9 검증 세트 정확도: 0.9634\n",
      "10 검증 세트 정확도: 0.9658\n",
      "11 검증 세트 정확도: 0.9664\n",
      "12 검증 세트 정확도: 0.9636\n",
      "13 검증 세트 정확도: 0.9676\n",
      "14 검증 세트 정확도: 0.9682\n",
      "15 검증 세트 정확도: 0.9686\n",
      "16 검증 세트 정확도: 0.9698\n",
      "17 검증 세트 정확도: 0.9666\n",
      "18 검증 세트 정확도: 0.9704\n",
      "19 검증 세트 정확도: 0.971\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = new_saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 모델을 만든 파이썬 코드에 접근할 수 있다면 필요한 부분만 재사용하고 나머지는 버릴 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # 재사용\n",
    "n_hidden2 = 50  # 재사용\n",
    "n_hidden3 = 50  # 재사용\n",
    "n_hidden4 = 20  # 새로 만듦!\n",
    "n_outputs = 10  # 새로 만듦!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # 재사용\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # 재사용\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # 재사용\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # 새로 만듦!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # 새로 만듦!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 이전에 학습된 모델을 복원하기 위해 (복원할 변수 리스트를 전달합니다. 그렇지 않으면 그래프와 맞지 않는다고 에러를 낼 것입니다) `Saver` 객체를 하나 만들고 훈련이 끝난 후 새로운 모델을 저장하기 위해 또 다른 `Saver` 객체를 만들어야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9016\n",
      "1 검증 세트 정확도: 0.933\n",
      "2 검증 세트 정확도: 0.943\n",
      "3 검증 세트 정확도: 0.947\n",
      "4 검증 세트 정확도: 0.9516\n",
      "5 검증 세트 정확도: 0.9534\n",
      "6 검증 세트 정확도: 0.9558\n",
      "7 검증 세트 정확도: 0.9592\n",
      "8 검증 세트 정확도: 0.9586\n",
      "9 검증 세트 정확도: 0.9608\n",
      "10 검증 세트 정확도: 0.9624\n",
      "11 검증 세트 정확도: 0.962\n",
      "12 검증 세트 정확도: 0.9638\n",
      "13 검증 세트 정확도: 0.9662\n",
      "14 검증 세트 정확도: 0.9662\n",
      "15 검증 세트 정확도: 0.9666\n",
      "16 검증 세트 정확도: 0.9672\n",
      "17 검증 세트 정확도: 0.9674\n",
      "18 검증 세트 정확도: 0.968\n",
      "19 검증 세트 정확도: 0.9676\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # 정규표현식\n",
    "restore_saver = tf.train.Saver(reuse_vars) # 1-3층 복원\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):                                        # 책에는 없음\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size): # 책에는 없음\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})    # 책에는 없음\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) # 책에는 없음\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)                      # 책에는 없음\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다른 프레임워크의 모델 재사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 예에서는 재사용하려는 각 변수에 대해 변수 초기화 할당 연산을 찾고, 초기화 될 값에 해당하는 두 번째 입력 핸들을 구합니다. 초기화가 실행될 때 여기에 `feed_dict` 매개변수를 사용하여 초깃값 대신 원하는 값을 주입합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # 다른 프레임워크로부터 가중치를 로드\n",
    "original_b = [7., 8., 9.]                 # 다른 프레임워크로부터 편향을 로드\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] 모델의 나머지 부분을 구성\n",
    "\n",
    "# hidden1 변수의 할당 노드에 대한 핸들을 구합니다\n",
    "graph = tf.get_default_graph()\n",
    "assign_kernel = graph.get_operation_by_name(\"hidden1/kernel/Assign\")\n",
    "assign_bias = graph.get_operation_by_name(\"hidden1/bias/Assign\")\n",
    "init_kernel = assign_kernel.inputs[1]\n",
    "init_bias = assign_bias.inputs[1]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, feed_dict={init_kernel: original_w, init_bias: original_b})\n",
    "    # [...] 새 작업에 모델을 훈련시킵니다\n",
    "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))  # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 방법은 전용 할당 노드와 플레이스홀더를 만든는 것입니다. 이 방법은 더 번거롭고 효율적이지 않지만 하려는 방식이 잘 드러나는 방법입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3\n",
    "\n",
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # 다른 프레임워크로부터 가중치를 로드\n",
    "original_b = [7., 8., 9.]                 # 다른 프레임워크로부터 편향을 로드\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] 모델의 나머지를 구성\n",
    "\n",
    "# hidden1 변수의 할당 노드에 대한 핸들을 구합니다\n",
    "with tf.variable_scope(\"\", default_name=\"\", reuse=True):  # 루트 범위 #reuse:공유된 변수 재사용\n",
    "    hidden1_weights = tf.get_variable(\"hidden1/kernel\")\n",
    "    hidden1_biases = tf.get_variable(\"hidden1/bias\")\n",
    "\n",
    "# 전용 플레이스홀더와 할당 노드를 만듭니다\n",
    "original_weights = tf.placeholder(tf.float32, shape=(n_inputs, n_hidden1))\n",
    "original_biases = tf.placeholder(tf.float32, shape=n_hidden1)\n",
    "assign_hidden1_weights = tf.assign(hidden1_weights, original_weights)\n",
    "assign_hidden1_biases = tf.assign(hidden1_biases, original_biases)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(assign_hidden1_weights, feed_dict={original_weights: original_w})\n",
    "    sess.run(assign_hidden1_biases, feed_dict={original_biases: original_b})\n",
    "    # [...] 새 작업에 모델을 훈련시킵니다\n",
    "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_collection()`에 `scope`를 지정하여 변수의 핸들을 가져올 수도 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden1/bias:0' shape=(3,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또는 그래프의 `get_tensor_by_name()` 메서드를 사용할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/bias:0' shape=(3,) dtype=float32_ref>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/bias:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하위층 동결하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 DNN의 하위층은 이미지에 있는 저수준 특성을 감지하도록 학습되어서 다른 이미지 분류 작업에 유용할 것 같습니다. 그러므로 이 층들은 그냥 있는 그대로 사용할 것 같습니다. 그러므로 이 층들은 그냥 있는 그대로 재사용할 수 있습니다. 일반적으로 새로은 DNN을 훈련시킬 때 재사용되는 층들의 가중치를 동결하는 것이 좋습니다. 하위층의 가중치가 고정되면(학습하려는 대상이 바뀌지 않기 때문에) 상위층의 가중치를 훈련시키기 쉽습니다. 훈련하는 동안 하위층을 고정시키는 한 가지 방법은 하위층의 변수를 제외하고 훈련시킬 변수 목록을 옵티마이저에 전달하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # 재사용\n",
    "n_hidden2 = 50  # 재사용\n",
    "n_hidden3 = 50  # 재사용\n",
    "n_hidden4 = 20  # 새로 만듦!\n",
    "n_outputs = 10  # 새로 만듦!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # 재사용\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # 재사용\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # 재사용\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # 새로 만듦!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # 새로 만듦!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):                                         # 책에는 없음\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)     # 책에는 없음\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                   scope=\"hidden[34]|outputs\")\n",
    "    training_op = optimizer.minimize(loss, var_list=train_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.8964\n",
      "1 검증 세트 정확도: 0.9302\n",
      "2 검증 세트 정확도: 0.9404\n",
      "3 검증 세트 정확도: 0.9442\n",
      "4 검증 세트 정확도: 0.948\n",
      "5 검증 세트 정확도: 0.9508\n",
      "6 검증 세트 정확도: 0.951\n",
      "7 검증 세트 정확도: 0.9534\n",
      "8 검증 세트 정확도: 0.9554\n",
      "9 검증 세트 정확도: 0.9566\n",
      "10 검증 세트 정확도: 0.956\n",
      "11 검증 세트 정확도: 0.9568\n",
      "12 검증 세트 정확도: 0.9572\n",
      "13 검증 세트 정확도: 0.958\n",
      "14 검증 세트 정확도: 0.9588\n",
      "15 검증 세트 정확도: 0.9578\n",
      "16 검증 세트 정확도: 0.9578\n",
      "17 검증 세트 정확도: 0.9602\n",
      "18 검증 세트 정확도: 0.9592\n",
      "19 검증 세트 정확도: 0.96\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # 정규 표현식\n",
    "restore_saver = tf.train.Saver(reuse_vars) # 1-3층 복원\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # 재사용\n",
    "n_hidden2 = 50  # 재사용\n",
    "n_hidden3 = 50  # 재사용\n",
    "n_hidden4 = 20  # 새로 만듦!\n",
    "n_outputs = 10  # 새로 만듦!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # 동결층 재사용\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # 동결층 재사용\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # 동결하지 않고 재사용\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # 새로 만듦!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # 새로 만듦!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련하는 코드는 이전과 완전히 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9022\n",
      "1 검증 세트 정확도: 0.9304\n",
      "2 검증 세트 정확도: 0.9432\n",
      "3 검증 세트 정확도: 0.9476\n",
      "4 검증 세트 정확도: 0.9514\n",
      "5 검증 세트 정확도: 0.9524\n",
      "6 검증 세트 정확도: 0.9522\n",
      "7 검증 세트 정확도: 0.9558\n",
      "8 검증 세트 정확도: 0.9554\n",
      "9 검증 세트 정확도: 0.9558\n",
      "10 검증 세트 정확도: 0.957\n",
      "11 검증 세트 정확도: 0.9554\n",
      "12 검증 세트 정확도: 0.9572\n",
      "13 검증 세트 정확도: 0.9578\n",
      "14 검증 세트 정확도: 0.9582\n",
      "15 검증 세트 정확도: 0.9574\n",
      "16 검증 세트 정확도: 0.9566\n",
      "17 검증 세트 정확도: 0.9578\n",
      "18 검증 세트 정확도: 0.9592\n",
      "19 검증 세트 정확도: 0.958\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # 정규 표현식\n",
    "restore_saver = tf.train.Saver(reuse_vars) # 1-3층 복원\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동결층 캐싱하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동결된 층은 변하지 않기 때문에 각 훈련 샘플에 대해 가장 위쪽의 동결된 층에서 나온 출력을 캐싱하는 것이 가능합니다. 전체 데이터셋에 대한 훈련이 여러 번 반복되기 때문에 훈련 샘플마다 동결된 처음 한 번만 거친다면 학습 속도를 크게 높일 수 있습니다. 예를 들어 전체 훈련 세트에 대해 하위층을 먼저 실행할 수 있습니다. 그리고 훈련하는 동안 훈련 샘플의 배치를 만드는 대신 은닉층 2의 출력을 배치로 만들어 훈련 연산에 주입합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # 재사용\n",
    "n_hidden2 = 50  # 재사용\n",
    "n_hidden3 = 50  # 재사용\n",
    "n_hidden4 = 20  # 새로 만듦!\n",
    "n_outputs = 10  # 새로 만듦!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # 동결층 재사용\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # 동결층 재사용 & 캐싱\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # 동결하지 않고 재사용\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # 새로 만듦!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # 새로 만듦!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # 정규 표현식\n",
    "restore_saver = tf.train.Saver(reuse_vars) # 1-3층 복원\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 검증 세트 정확도: 0.9022\n",
      "1 검증 세트 정확도: 0.9304\n",
      "2 검증 세트 정확도: 0.9432\n",
      "3 검증 세트 정확도: 0.9476\n",
      "4 검증 세트 정확도: 0.9514\n",
      "5 검증 세트 정확도: 0.9524\n",
      "6 검증 세트 정확도: 0.9522\n",
      "7 검증 세트 정확도: 0.9558\n",
      "8 검증 세트 정확도: 0.9554\n",
      "9 검증 세트 정확도: 0.9558\n",
      "10 검증 세트 정확도: 0.957\n",
      "11 검증 세트 정확도: 0.9554\n",
      "12 검증 세트 정확도: 0.9572\n",
      "13 검증 세트 정확도: 0.9578\n",
      "14 검증 세트 정확도: 0.9582\n",
      "15 검증 세트 정확도: 0.9574\n",
      "16 검증 세트 정확도: 0.9566\n",
      "17 검증 세트 정확도: 0.9578\n",
      "18 검증 세트 정확도: 0.9592\n",
      "19 검증 세트 정확도: 0.958\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_batches = len(X_train) // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "    h2_cache = sess.run(hidden2, feed_dict={X: X_train})\n",
    "    h2_cache_valid = sess.run(hidden2, feed_dict={X: X_valid}) # 책에는 없음\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_idx = np.random.permutation(len(X_train))\n",
    "        hidden2_batches = np.array_split(h2_cache[shuffled_idx], n_batches)\n",
    "        y_batches = np.array_split(y_train[shuffled_idx], n_batches)\n",
    "        for hidden2_batch, y_batch in zip(hidden2_batches, y_batches):\n",
    "            sess.run(training_op, feed_dict={hidden2:hidden2_batch, y:y_batch})\n",
    "\n",
    "        accuracy_val = accuracy.eval(feed_dict={hidden2: h2_cache_valid, # 책에는 없음\n",
    "                                                y: y_valid})             # 책에는 없음\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)                      # 책에는 없음\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비지도 사전훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"unsuperv.png\", width = \"500\" ><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 고속 옵티마이저"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss function의 현 가중치에서 기울기(gradient)를 줄여 loss를 줄이는 방법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하용호님이 생각하는 [옵티마이저](https://www.slideshare.net/yongho/ss-79607172)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"Ha_optimizer.png\", width = \"500\" ><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 출처: [모두의 딥러닝](https://kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&ejkGb=KOR&barcode=9791160503715&orderClick=JAj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"sig_03.jpeg\" width=\"500\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"sig_04.jpeg\" width=\"500\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능비교 :  https://emcslabs.github.io/machinelearning/AdamOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"optimizer.png\" width=\"700\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모멘텀 옵티마이저"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모멘텀 최적화는 이전 그래디언트가 얼마였는지를 상당히 중요하게 생각합니다. 매 반복에서 현재 그래디언트를 (학습률 η를 곱한 후  )모멘텀 벡터 m에 더하고 이 값을 빼는 방식으로 가중치를 갱신합니다. 즉 그래디언트를 속도가 아니라 가속도로 시용합니다. 일종의 마찰저항을 표현하고 모멘텀이 너무 커지는 것을 막기 위해 이 알고리즘에 모멘텀이라는 새로운 하이퍼파라미터 β가 등장합니다. 이 값는 0(높은 마찰저항)롸 1(마찰저항 없음) 사이로 설정되어야 합니다. 일반적인 모멤텀 값은 0.9입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"momentum.png\", width=\"200\"><BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"N_momentum.png\", \"width = 500\"><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네스테로프 가속 경사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9, use_nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate,\n",
    "                                      momentum=0.9, decay=0.9, epsilon=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습률 스케줄링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"learning_curve.png\", \"width = 500\"><BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):       # 책에는 없음\n",
    "    initial_learning_rate = 0.1\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 1/10\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step,\n",
    "                                               decay_steps, decay_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9618\n",
      "1 검증 세트 정확도: 0.9754\n",
      "2 검증 세트 정확도: 0.975\n",
      "3 검증 세트 정확도: 0.9828\n",
      "4 검증 세트 정확도: 0.9812\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 규제로 과대적합 피하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 세트에 과대적합하기 것을 피하기 위한 좋은 방법 중 하나는 4장에서 소개한 조기 종료입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 $\\ell_1$과 $\\ell_2$ 규제를 사용해서도 가중치에 제약을 가할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로를 사용해 이를 구현하는 방법은 비용 함수에 적절한 규제항을 추가하는 것입니다. 가증치 W1인 하나의 은닉층과 가중치가 W2인 출력층이 있다면 다음과 같이 규제할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ell_1$과 $\\ell_2$ 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\ell_1$ 규제를 직접 구현해 보죠. 먼저 평상시처럼 모델을 만듭니다(간단하게 하기 위해 은닉층을 하나만 두겠습니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그다음, 층의 가중치에 대한 핸들을 얻어 크로스 엔트로피 손실에 $\\ell_1$ 손실(즉, 가중치의 절댓값)을 더해 전체 손실을 계산합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "W2 = tf.get_default_graph().get_tensor_by_name(\"outputs/kernel:0\")\n",
    "\n",
    "scale = 0.001 # l1 규제 하이퍼파라미터\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")\n",
    "    reg_losses = tf.reduce_sum(tf.abs(W1)) + tf.reduce_sum(tf.abs(W2))\n",
    "    loss = tf.add(base_loss, scale * reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나머지는 이전과 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.831\n",
      "1 검증 세트 정확도: 0.871\n",
      "2 검증 세트 정확도: 0.8838\n",
      "3 검증 세트 정확도: 0.8934\n",
      "4 검증 세트 정확도: 0.8966\n",
      "5 검증 세트 정확도: 0.8988\n",
      "6 검증 세트 정확도: 0.9016\n",
      "7 검증 세트 정확도: 0.9044\n",
      "8 검증 세트 정확도: 0.9058\n",
      "9 검증 세트 정확도: 0.906\n",
      "10 검증 세트 정확도: 0.9068\n",
      "11 검증 세트 정확도: 0.9054\n",
      "12 검증 세트 정확도: 0.907\n",
      "13 검증 세트 정확도: 0.9084\n",
      "14 검증 세트 정확도: 0.9088\n",
      "15 검증 세트 정확도: 0.9064\n",
      "16 검증 세트 정확도: 0.9068\n",
      "17 검증 세트 정확도: 0.9066\n",
      "18 검증 세트 정확도: 0.9066\n",
      "19 검증 세트 정확도: 0.9052\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 방법으로는 `tf.layers.dense()` 함수에 규제 함수를 전달할 수 있습니다. 이 함수는 규제 손실을 계산하기 위한 연산을 만들고 규제 손실 컬렉션에 이 연산을 추가합니다. 모델 선언부는 이전과 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일한 매개변수를 매번 반복하지 않으려고 파이썬의 `partial()` 함수를 사용합니다. `kernel_regularizer` 매개변수를 지정해야 합니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regularizer(scale)는 가중치를 매개변수로 내려받아 규제에 상응하는 손실을 반환하는 함수를 이 매개변수에 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dense_layer = partial(\n",
    "    tf.layers.dense, activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.contrib.layers.l1_regularizer(scale))\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden2, name=\"hidden2\")\n",
    "    logits = my_dense_layer(hidden2, n_outputs, activation=None,\n",
    "                            name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드는 두 개의 은닉층과 한 개의 출력층으로 이루어진 신경망을 만들고 각 층의 가중치에 상응하는 규제 손실을 계산하기 위한 노드도 그래프에 추가합니다. 텐서플로는 모든 규제 손실을 포함하는 특별한 콜렉션에 이런 노드를 자동으로 추가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 기본 손실에 규제 손실을 추가해 주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):                                     # 책에는 없음\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(  # 책에는 없음\n",
    "        labels=y, logits=logits)                                # 책에는 없음\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")   # 책에는 없음\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([base_loss] + reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나머지는 평상시와 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.8274\n",
      "1 검증 세트 정확도: 0.8766\n",
      "2 검증 세트 정확도: 0.8952\n",
      "3 검증 세트 정확도: 0.9016\n",
      "4 검증 세트 정확도: 0.9082\n",
      "5 검증 세트 정확도: 0.9096\n",
      "6 검증 세트 정확도: 0.9126\n",
      "7 검증 세트 정확도: 0.9154\n",
      "8 검증 세트 정확도: 0.9178\n",
      "9 검증 세트 정확도: 0.919\n",
      "10 검증 세트 정확도: 0.92\n",
      "11 검증 세트 정확도: 0.9224\n",
      "12 검증 세트 정확도: 0.9212\n",
      "13 검증 세트 정확도: 0.9228\n",
      "14 검증 세트 정확도: 0.9224\n",
      "15 검증 세트 정확도: 0.9216\n",
      "16 검증 세트 정확도: 0.9218\n",
      "17 검증 세트 정확도: 0.9228\n",
      "18 검증 세트 정확도: 0.9216\n",
      "19 검증 세트 정확도: 0.9214\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 드롭아웃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2012년 제프리 힌튼 등이 제안(https://arxiv.org/pdf/1207.0580.pdf) 했습니다. \n",
    "\n",
    "1. 매 훈련 스텝에서 임시적으로 드롭아웃될 확률 p를 가집니다. 즉 이번 훈련 스텝에는 완전히 무시되지만 다음 스텝에는 활성화될 수 있습니다. 보통 50%의 드롭아웃을 지정합니다.        \n",
    "\n",
    "2. 드롭아웃을 이해하는 두 번째 방법은 각 훈련 스텝마다 고유한 네트워크가 생성된다고 생각하는 것입니다. 개개의 뉴런이 있을 수도 있고 없을 수도 있기 때문에 2*개의 네트워크가 가능합니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"dropout.png\", width = \"500\"><BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "dropout_rate = 0.5  # == 1 - keep_prob\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    logits = tf.layers.dense(hidden2_drop, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 종류의 드롭아웃에 대한 논문       \n",
    "\n",
    "A Bayesian Encourages Dropout\n",
    "https://arxiv.org/abs/1412.7003\n",
    "\n",
    "\n",
    "\n",
    "Variational Dropout and the Local Reparameterization Trick\n",
    "http://arxiv.org/abs/1506.02557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9254\n",
      "1 검증 세트 정확도: 0.9452\n",
      "2 검증 세트 정확도: 0.9492\n",
      "3 검증 세트 정확도: 0.9566\n",
      "4 검증 세트 정확도: 0.9618\n",
      "5 검증 세트 정확도: 0.9602\n",
      "6 검증 세트 정확도: 0.96\n",
      "7 검증 세트 정확도: 0.9674\n",
      "8 검증 세트 정확도: 0.969\n",
      "9 검증 세트 정확도: 0.9706\n",
      "10 검증 세트 정확도: 0.9692\n",
      "11 검증 세트 정확도: 0.9694\n",
      "12 검증 세트 정확도: 0.9712\n",
      "13 검증 세트 정확도: 0.9716\n",
      "14 검증 세트 정확도: 0.9714\n",
      "15 검증 세트 정확도: 0.9706\n",
      "16 검증 세트 정확도: 0.9712\n",
      "17 검증 세트 정확도: 0.9716\n",
      "18 검증 세트 정확도: 0.9726\n",
      "19 검증 세트 정확도: 0.9736\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 맥스 노름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2개의 은닉층을 가진 간단한 MNIST 신경망을 만들어 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 첫 번째 은닉층의 가중치에 대한 핸들을 얻고 `clip_by_norm()` 함수를 사용해 가중치를 클리핑하는 연산을 만듭니다. 그런 다음 클리핑된 가중치를 가중치 변수에 할당하는 연산을 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/clip_ops.py:110: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "threshold = 1.0\n",
    "weights = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "clipped_weights = tf.clip_by_norm(weights, clip_norm=threshold, axes=1)\n",
    "clip_weights = tf.assign(weights, clipped_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 번째 층에 대해서도 동일하게 할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2 = tf.get_default_graph().get_tensor_by_name(\"hidden2/kernel:0\")\n",
    "clipped_weights2 = tf.clip_by_norm(weights2, clip_norm=threshold, axes=1)\n",
    "clip_weights2 = tf.assign(weights2, clipped_weights2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초기와 연산과 `Saver` 객체를 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 훈련시킵니다. 이전과 매우 동일한데 `training_op`을 실행한 후에 `clip_weights`와 `clip_weights2` 연산을 실행하는 것만 다릅니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9568\n",
      "1 검증 세트 정확도: 0.9702\n",
      "2 검증 세트 정확도: 0.9718\n",
      "3 검증 세트 정확도: 0.9774\n",
      "4 검증 세트 정확도: 0.9772\n",
      "5 검증 세트 정확도: 0.9782\n",
      "6 검증 세트 정확도: 0.9822\n",
      "7 검증 세트 정확도: 0.9816\n",
      "8 검증 세트 정확도: 0.9804\n",
      "9 검증 세트 정확도: 0.9818\n",
      "10 검증 세트 정확도: 0.9824\n",
      "11 검증 세트 정확도: 0.9848\n",
      "12 검증 세트 정확도: 0.9822\n",
      "13 검증 세트 정확도: 0.9836\n",
      "14 검증 세트 정확도: 0.9844\n",
      "15 검증 세트 정확도: 0.9844\n",
      "16 검증 세트 정확도: 0.9844\n",
      "17 검증 세트 정확도: 0.9846\n",
      "18 검증 세트 정확도: 0.9852\n",
      "19 검증 세트 정확도: 0.9848\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:                                              # 책에는 없음\n",
    "    init.run()                                                          # 책에는 없음\n",
    "    for epoch in range(n_epochs):                                       # 책에는 없음\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):  # 책에는 없음\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            clip_weights.eval()\n",
    "            clip_weights2.eval()                                        # 책에는 없음\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) # 책에는 없음\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)                     # 책에는 없음\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")               # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 구현은 이해하기 쉽고 잘 작동하지만 조금 번거롭습니다. 더 나은 방법은 `max_norm_regularizer()` 함수를 만드는 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_norm_regularizer(threshold, axes=1, name=\"max_norm\",\n",
    "                         collection=\"max_norm\"):\n",
    "    def max_norm(weights):\n",
    "        clipped = tf.clip_by_norm(weights, clip_norm=threshold, axes=axes)\n",
    "        clip_weights = tf.assign(weights, clipped, name=name)\n",
    "        tf.add_to_collection(collection, clip_weights)\n",
    "        return None # 규제 손실을 위한 항이 없습니다\n",
    "    return max_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런 다음 (필요한 임계값을 지정해서) 맥스 노름 규제 매개변수에 넘길 함수를 만들기 위해 이 함수를 호출합니다. 은닉층을 만들 때 이 규제 함수를 `kernel_regularizer` 매개변수를 통해 전달할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm_reg = max_norm_regularizer(threshold=1.0)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 연산이 실행된 후에 가중치 클리핑 연산을 실행하는 것을 제외하면 이전과 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 검증 세트 정확도: 0.9556\n",
      "1 검증 세트 정확도: 0.9706\n",
      "2 검증 세트 정확도: 0.9688\n",
      "3 검증 세트 정확도: 0.975\n",
      "4 검증 세트 정확도: 0.9774\n",
      "5 검증 세트 정확도: 0.976\n",
      "6 검증 세트 정확도: 0.9812\n",
      "7 검증 세트 정확도: 0.9798\n",
      "8 검증 세트 정확도: 0.9828\n",
      "9 검증 세트 정확도: 0.982\n",
      "10 검증 세트 정확도: 0.9804\n",
      "11 검증 세트 정확도: 0.983\n",
      "12 검증 세트 정확도: 0.9822\n",
      "13 검증 세트 정확도: 0.9836\n",
      "14 검증 세트 정확도: 0.9838\n",
      "15 검증 세트 정확도: 0.9842\n",
      "16 검증 세트 정확도: 0.9832\n",
      "17 검증 세트 정확도: 0.9828\n",
      "18 검증 세트 정확도: 0.9844\n",
      "19 검증 세트 정확도: 0.9838\n"
     ]
    }
   ],
   "source": [
    "clip_all_weights = tf.get_collection(\"max_norm\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            sess.run(clip_all_weights)\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) # 책에는 없음\n",
    "        print(epoch, \"검증 세트 정확도:\", accuracy_val)                      # 책에는 없음\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")                # 책에는 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 연습문제 해답"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11장의 연습문제는 [11_deep_learning_exercise](11_deep_learning_exercises.ipynb) 노트북에 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
